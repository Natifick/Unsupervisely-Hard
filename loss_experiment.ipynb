{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightly\n",
    "# !pip install scikit-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "SEED=42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils and metrics\n",
    "from skdim.id import MLE # Maximum-Likelihood ID esimation\n",
    "\n",
    "def model_param_count(model):\n",
    "    return sum([np.prod(p.shape) for p in model.parameters()])\n",
    "\n",
    "class MeanSquareDistancesStat:\n",
    "    def __init__(self, ds_size, batch_size, model, n_epochs, hidden_dim):\n",
    "        \"\"\"\n",
    "        ds_size: size of dataset\n",
    "        batch_size: size of batch\n",
    "        model: encoder that is expected to return representations of size (batch_size, hidden_dim)\n",
    "        hidden_dim: dimension of representations\n",
    "        \"\"\"\n",
    "        self.last_epoch_repr = torch.zeros(ds_size, hidden_dim)\n",
    "        self.mdp_hist = torch.zeros((n_epochs, ds_size))\n",
    "        self.encoder = model\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_samples = ds_size\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "        self.cur_batch = 0\n",
    "        self.cur_epoch = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def mdp(self, x_prev, x_next):\n",
    "        return torch.mean((x_next - x_prev) ** 2, dim=1)\n",
    "\n",
    "    def push(self, x_batch):\n",
    "        if self.cur_epoch == self.n_epochs: raise ValueError('Statistics is already collected')\n",
    "        \n",
    "        l, r = self.cur_batch * self.batch_size, (self.cur_batch + 1) * self.batch_size\n",
    "        \n",
    "        x_repr_cur = self.encoder(x_batch)\n",
    "        x_repr_prev = self.last_epoch_repr[l:r]\n",
    "\n",
    "        self.mdp_hist[self.cur_epoch, l:r] = self.mdp(x_repr_prev, x_repr_cur).cpu()\n",
    "        \n",
    "        self.last_epoch_repr[l:r] = x_repr_cur\n",
    "        self.cur_batch += 1\n",
    "\n",
    "        if self.cur_batch * self.batch_size >= self.n_samples:\n",
    "            self.cur_batch = 0\n",
    "            self.cur_epoch += 1\n",
    "\n",
    "class IDStats:\n",
    "    def __init__(self, ds_size:int, mle_kwargs):\n",
    "        self.ds_size = ds_size\n",
    "        self.id_hist = []\n",
    "\n",
    "        self.mle_est = MLE(**mle_kwargs)\n",
    "\n",
    "    def push(self, x_enc):\n",
    "        assert x_enc.shape[0] == self.ds_size\n",
    "        self.id_hist.append(self.mle_est.fit_transform_pw(x_enc))\n",
    "        \n",
    "        # QUESTION: should we:\n",
    "        # - fit to train => predict on test\n",
    "        # - fit on test => predict on test\n",
    "        # - fit on train => predict on train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Contrastive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barlow Twins\n",
    "https://arxiv.org/abs/2103.03230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.loss import BarlowTwinsLoss\n",
    "from lightly.models.modules import BarlowTwinsProjectionHead\n",
    "from lightly.transforms.byol_transform import (\n",
    "    BYOLView1Transform,\n",
    "    BYOLView2Transform,\n",
    "    MultiViewTransform\n",
    ")\n",
    "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
    "\n",
    "class BarlowTwins(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CHS = 3\n",
    "IMG_SIZE = (32, 32)\n",
    "BS = 256\n",
    "\n",
    "class BYOLTransformWrapped(MultiViewTransform):\n",
    "        \"\"\"Appends BYOL transform output with not augmented images\"\"\"\n",
    "        def __init__(self, view_1_transform, view_2_transform):\n",
    "                view_1_transform = view_1_transform or BYOLView1Transform()\n",
    "                view_2_transform = view_2_transform or BYOLView2Transform()\n",
    "                transforms = [\n",
    "                        T.Compose([T.ToTensor(), T.Normalize(mean=IMAGENET_NORMALIZE[\"mean\"], std=IMAGENET_NORMALIZE[\"std\"])]),\n",
    "                        view_1_transform, \n",
    "                        view_2_transform\n",
    "                ]\n",
    "                super().__init__(transforms=transforms)\n",
    "\n",
    "\n",
    "transform = BYOLTransformWrapped( # note: this thing works only with 3\n",
    "        view_1_transform=BYOLView1Transform(input_size=IMG_SIZE[0], gaussian_blur=0.0),\n",
    "        view_2_transform=BYOLView2Transform(input_size=IMG_SIZE[0], gaussian_blur=0.0),\n",
    ")\n",
    "\n",
    "ds = datasets.CIFAR10(root='./data', transform=transform, download=True)\n",
    "loader = DataLoader(ds, batch_size=BS, shuffle=True, drop_last=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, torch.Size([64, 3, 32, 32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds), next(iter(loader))[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836032\n"
     ]
    }
   ],
   "source": [
    "backbone = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(CHS*np.prod(IMG_SIZE), 512),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.ELU()\n",
    ")\n",
    "\n",
    "print(model_param_count(backbone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 125/195 [04:45<02:34,  2.21s/it]"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10\n",
    "\n",
    "model = BarlowTwins(backbone).to(DEVICE)\n",
    "criterion = BarlowTwinsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
    "\n",
    "msd_tracker = MeanSquareDistancesStat(len(ds), BS, model, NUM_EPOCHS, hidden_dim=2048)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for x, _ in tqdm(loader):\n",
    "        x_orig, x0, x1 = x\n",
    "        x_orig = x_orig.to(DEVICE)\n",
    "        x0 = x0.to(DEVICE)\n",
    "        x1 = x1.to(DEVICE)\n",
    "\n",
    "        z0 = model(x0)\n",
    "        z1 = model(x1)\n",
    "\n",
    "        loss = criterion(z0, z1)\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "\n",
    "        msd_tracker.push(x_orig)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-std",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
